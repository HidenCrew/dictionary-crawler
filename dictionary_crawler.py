# -*- coding: utf-8 -*-
"""dictionary_crawler.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EUAME9jUCXngIkdkRaSD6B4XnAJ0NEbx

# Install required packages for one time usage
"""

# install python-docx to write to doc
!pip install python-docx
!pip show python-docx

"""# Install required packages permanently"""

import os, sys
from google.colab import drive
# Create a symbolic link with no whitespace to the Colab notebooks, and put that in PATH.
drive.mount('/content/drive')
softlink = '/content/notebooks_link'
os.symlink('/content/drive/My Drive/Colab Notebooks', softlink)
sys.path.insert(0,softlink)

!pip install --target=$softlink python-docx
#TODO: Check why we can't find docx here
!pip show python-docx

"""# Put in words"""

# put in words
words = ['invertebrate', 'camouflage', 'gratification', 'gra', 'rat-run', 'obese', 'crosshair', '']
print(words)

"""# Data processing"""

# TODO: Check that whether we need to mount the drive first to find docx?
from google.colab import drive
drive.mount('/content/drive')

import requests
from bs4 import BeautifulSoup
import re
import docx

class Definition():
  def __init__(self, meaning):
    self.meaning = meaning.text
    print('meaning: ' + self.meaning)
    # chinese
    self.chinese = meaning.next_sibling.find('span', {'lang': 'zh-Hant'}).text
    print('chinese: ' + self.chinese)
    # examples
    self.examples = []
    for example in meaning.next_sibling.find_all('div', {'class': 'examp'}):
      self.examples.append(re.sub('\n$', '', example.text))
    print(self.examples)


class WordData():
  def __init__(self, word):
    # Make the request to a url
    r = requests.get('https://dictionary.cambridge.org/dictionary/english-chinese-traditional/' + word,
              headers = {'user-agent':'Mozilla/5.0 (Windows NT 6.0; WOW64; rv:24.0) Gecko/20100101 Firefox/24.0'})
    soup = BeautifulSoup(r.content)

    # get the title
    title = soup.find('title').text
    print('raw title: ' + title)
    self.title = re.sub(' \|.*', '', title)
    print('clean title: ' + self.title)

    # get the pronouciation
    self.pronunciations = []
    for pron in soup.find_all('span', {'class': 'pron'}):
      print('pron: ' + pron.text)
      self.pronunciations.append(pron.text)
    print(self.pronunciations)

    # get the meaning
    self.definitions = []
    for meaning in soup.find_all('div', {'class': 'ddef_h'}):
      self.definitions.append(Definition(meaning))

  def ToDoc(self, doc):
    p = doc.add_paragraph(self.title, style='List Bullet')
    p.add_run('\n')
    first = True
    for pron in self.pronunciations:
      if not first:
        p.add_run(', ')
      first = False
      p.add_run(pron)
    
    for definition in self.definitions:
      p = doc.add_paragraph(definition.meaning, style='List Bullet 2')
      p.add_run('\n')
      p.add_run(definition.chinese)
      for example in definition.examples:
        doc.add_paragraph(example, style='List Bullet 3')

# Processing
doc = docx.Document()
for word in words:
  wordData = WordData(word)
  wordData.ToDoc(doc)

# Output the file to the drive
doc.save('/content/drive/MyDrive/helloWorld.docx')

